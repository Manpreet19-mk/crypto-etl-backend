 Crypto ETL Backend

A Dockerized backend service that performs ETL (Extract, Transform, Load) operations on cryptocurrency market data using public APIs and stores the data in PostgreSQL. The project exposes REST APIs using FastAPI to trigger ETL jobs and retrieve stored data.



ğŸš€ Features

- Fetches real-time cryptocurrency prices from:
  - CoinGecko (public API)
  - CoinPaprika (public API)
- Stores normalized crypto price data in PostgreSQL
- REST API built using FastAPI
- Dockerized setup using Docker Compose
- Swagger UI for API testing
- Modular ETL architecture (ingestion, services, API layers)



 ğŸ§± Tech Stack

- **Backend**: FastAPI (Python)
- **Database**: PostgreSQL
- **ORM**: SQLAlchemy
- **ETL**: Custom Python ingestion modules
- **Containerization**: Docker & Docker Compose
- **API Docs**: Swagger (OpenAPI)



 ğŸ“‚ Project Structure

crypto-etl-backend/
â”‚
â”œâ”€â”€ api/
â”‚ â””â”€â”€ main.py # FastAPI entry point
â”‚
â”œâ”€â”€ ingestion/
â”‚ â”œâ”€â”€ coingecko.py # CoinGecko ingestion logic
â”‚ â”œâ”€â”€ coinpaprika.py # CoinPaprika ingestion logic
â”‚ â””â”€â”€ etl_runner.py # Orchestrates ETL process
â”‚
â”œâ”€â”€ services/
â”‚ â”œâ”€â”€ db.py # Database connection
â”‚ â””â”€â”€ models.py # SQLAlchemy models
â”‚
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

yaml
 âš™ï¸ Setup Instructions

 1ï¸âƒ£ Prerequisites

- Docker
- Docker Compose



 2ï¸âƒ£ Clone Repository

git clone https://github.com/<your-username>/crypto-etl-backend.git
cd crypto-etl-backend


3ï¸âƒ£ Run the Application

docker-compose up --build
The API will start at:
http://localhost:8000
ğŸ“˜ API Endpoints
ğŸ”¹ Swagger UI

http://localhost:8000/docs
ğŸ”¹ Health Check
GET /health
Response

{
  "db": "connected"
}

ğŸ”¹ Trigger ETL Job
POST /etl/run

Response

{
  "status": "ETL completed"
}
ğŸ”¹ Fetch Stored Data
GET /data
Response

[
  {
    "source": "coingecko",
    "symbol": "btc",
    "name": "Bitcoin",
    "price_usd": 43000,
    "timestamp": "2025-12-25T16:40:00"
  }
]
ğŸ” API Keys
This project uses public endpoints

No API keys are required

Architecture supports environment-based API keys if needed in future

ğŸ§ª Notes
ETL can be triggered manually via API

Database persists using Docker volumes

Designed for backend / data engineering assignments

ğŸ‘©â€ğŸ’» Author
Manpreet Kaur
Final Year CSE Student
Backend & Data Engineering Enthusiast

